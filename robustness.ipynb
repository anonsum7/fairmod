{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import fairness_metrics\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data\n",
    "ideology_df = pd.read_csv('./data/processed_annotated_comments.csv')\n",
    "ideology_df['label'] = ideology_df['label'].apply(lambda x: None if x not in ['left', 'right'] else x)\n",
    "ideology_df.dropna(inplace=True)\n",
    "gender_df = pd.read_csv('./data/jigsaw/gender.csv')\n",
    "race_df = pd.read_csv('./data/jigsaw/race.csv')\n",
    "disability_df = pd.read_csv('./data/jigsaw/disability.csv')\n",
    "sexual_orientation_df = pd.read_csv('./data/jigsaw/sexual_orientation.csv')\n",
    "dfs = [ideology_df, gender_df, race_df, disability_df, sexual_orientation_df]\n",
    "names = ['ideology', 'gender', 'race', 'disability', 'sexual orientation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load gold standard moderation if raw results are saved\n",
    "\n",
    "# with open('./results/<openai_moderation>.pkl', 'rb') as handle: # comments_moderated_openai\n",
    "#     gold1 = pickle.load(handle)\n",
    "\n",
    "# with open('./results/<perspective_moderation>.pkl', 'rb') as handle: # comments_moderated_perspective_nonmanager\n",
    "#     gold2 = pickle.load(handle)\n",
    "\n",
    "# with open('./results/<google_palm_moderation>.pkl', 'rb') as handle: # comments_moderation_google\n",
    "#     gold3 = pickle.load(handle)\n",
    "\n",
    "# with open('./results/<clarifai_moderation>.pkl', 'rb') as handle: # comment_moderation_clarifai\n",
    "#     gold4 = pickle.load(handle)\n",
    "\n",
    "# gold1 = utils.process_openai(gold1)\n",
    "# gold2 = utils.process_perspective(gold2)\n",
    "# gold3 = utils.process_google(gold3)\n",
    "# gold4 = utils.process_clarifai(gold4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load preprocessed results\n",
    "with open('./results/moderation_results.pkl', 'rb') as file:\n",
    "    fairness_results = pickle.load(file)\n",
    "\n",
    "\n",
    "gold1 = {k:v['openai'] for k,v in fairness_results.items()}\n",
    "gold2 = {k:v['perspective'] for k,v in fairness_results.items()}\n",
    "gold3 = {k:v['google'] for k,v in fairness_results.items() if v['google'] in [True, False]}\n",
    "gold4 = {k:v['clarifai'] for k,v in fairness_results.items()}\n",
    "\n",
    "gold1 = {k: 1 if v is True else 0 for k,v in gold1.items()}\n",
    "gold2 = {k: 1 if v is True else 0 for k,v in gold2.items()}\n",
    "gold3 = {k:1 if v is True else 0 for k,v in gold3.items()}\n",
    "gold4 = {k:1 if v is True else 0 for k,v in gold4.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "golds = [gold1, gold2, gold3, gold4]\n",
    "\n",
    "methods = ['openai', 'perspective','google', 'clarifai']\n",
    "perturbations = ['german', 'gpt_3.5_turbo']\n",
    "\n",
    "results = []\n",
    "global_results = {}\n",
    "for method in methods:\n",
    "    global_results[method] = {}\n",
    "\n",
    "perturbation_map = {}\n",
    "\n",
    "\n",
    "with open('./results/comments_backtranslated_german_similarity.pkl', 'rb') as handle:\n",
    "        perturbation_map[perturbations[0]] = pickle.load(handle)\n",
    "\n",
    "with open('./results/comment_paraphrased_gpt-3.5_final.pkl', 'rb') as handle:\n",
    "        perturbation_map[perturbations[1]] = pickle.load(handle)\n",
    "\n",
    "for perturbation in perturbations:\n",
    "    with open(f'./results/moderation_results_fairness_perturbed_{perturbation}.pkl', 'rb') as handle:\n",
    "        fairness_results = pickle.load(handle)\n",
    "    \n",
    "    phrase_map = perturbation_map[perturbation]\n",
    "    if perturbation == \"german\":\n",
    "        phrase_map = {k:v['augmented'] for k,v in phrase_map.items() if v['score'] > 0.85 and v['score'] != 1.0}\n",
    "\n",
    "    for gold, method in zip(golds, methods):\n",
    "        local_gold = gold.copy()\n",
    "        \n",
    "        # check to ignore NULL values for phrases where moderation did not run\n",
    "        fairness_results = {k:v for k,v in fairness_results.items() if fairness_results[k][method] in [True, False]}\n",
    "        \n",
    "        data = {k:int(fairness_results[v][method]) for k,v in phrase_map.items() if v in fairness_results.keys()}\n",
    "\n",
    "        local_gold = {k:v for k,v in local_gold.items() if k in data.keys() and v in [True, False]}\n",
    "\n",
    "        # create lists and compute robustness\n",
    "        global_results[method][perturbation] = {}\n",
    "        for subset, name in zip(dfs, names):\n",
    "            df = subset.copy()\n",
    "            df = df[df['text'].isin(list(local_gold.keys()))]\n",
    "            a = [local_gold[k] for k in df['text'].tolist()]\n",
    "            b = [data[k] for k in df['text'].tolist()]\n",
    "            \n",
    "            r = fairness_metrics.robustness(a, b)\n",
    "            global_results[method][perturbation][name] = r*100\n",
    "            print(r*100, method, perturbation, name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mod",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
